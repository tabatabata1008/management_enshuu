{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#必要なモジュールをインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#可視化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#単回帰分析\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#ロジスティック回帰\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score,roc_auc_score,roc_curve, auc\n",
    "\n",
    "import datetime as dt\n",
    "from mpl_toolkits.mplot3d import Axes3D  #3Dplot\n",
    "from sklearn import preprocessing #標準化\n",
    "\n",
    "from datetime import datetime\n",
    "# 標準化\n",
    "import scipy\n",
    "#可視化\n",
    "import matplotlib.pyplot as plt\n",
    "# k-means\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import xlrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import dask.dataframe as dd\n",
    "from os import listdir\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 300)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各データ読み込み"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくばみどりの店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくばみどりの店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくばみらい伊奈店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくばみらい伊奈店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば学園吾妻店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば学園吾妻店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば学園中央店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば学園中央店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば学園二の宮店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば学園二の宮店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば学園並木店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば学園並木店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば吉沼店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば吉沼店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば研究学園店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば研究学園店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば研究学園北店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば研究学園北店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\3年講義\\\\秋学期\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\3年講義\\\\秋学期\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば桜店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\3年講義\\\\秋学期\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば桜店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば松代店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば松代店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば大穂店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば大穂店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば谷田部店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば谷田部店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば東店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば東店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば豊里店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば豊里店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば北条店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば北条店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#各店舗フォルダがあるパスを取得\n",
    "path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output'\n",
    "folda_path = [filename for filename in listdir(path) if not filename.startswith('.')]\n",
    "\n",
    "#店舗フォルダごとにfor文を回す\n",
    "for i in range(1):\n",
    "    pre_path ='C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば万博記念公園店'.format(folda_path[i])\n",
    "    data_path = [filename for filename in listdir(pre_path) if not filename.startswith('.')]\n",
    "    #各店舗の月ごとにfor文を回す\n",
    "for j in range(36):\n",
    "    df_raw = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\マネジメント演習\\\\本データ\\\\output\\\\つくば万博記念公園店\\\\{}'.format(data_path[j]),encoding = \"shift_jis\")\n",
    "    if j == 0:\n",
    "        df_tempo = df_raw\n",
    "    else:\n",
    "        df_tempo = pd.concat([df_tempo, df_raw], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\3年講義\\\\秋学期\\\\マネジメント演習\\\\本データ\\\\気象データ\\\\つくば市気象データ2017.9-2018.8.csv',encoding = \"shift_jis\")\n",
    "w2 = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\3年講義\\\\秋学期\\\\マネジメント演習\\\\本データ\\\\気象データ\\\\つくば市気象データ2018.9-2019.8.csv',encoding = \"shift_jis\")\n",
    "w3 = pd.read_csv('C:\\\\Users\\\\taban\\\\Desktop\\\\3年講義\\\\秋学期\\\\マネジメント演習\\\\本データ\\\\気象データ\\\\つくば市気象データ2019.9-2020.8.csv',encoding = \"shift_jis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = w1.dropna()\n",
    "w2 = w2.dropna()\n",
    "w3 = w3.dropna()\n",
    "\n",
    "w1 = w1.drop(w1.index[0])\n",
    "w2 = w2.drop(w2.index[0])\n",
    "w3 = w3.drop(w3.index[0])\n",
    "\n",
    "w1 = w1.drop(['Unnamed: 2', 'Unnamed: 3'], axis=1)\n",
    "w2 = w2.drop(['Unnamed: 2', 'Unnamed: 3'], axis=1)\n",
    "w3 = w3.drop(['Unnamed: 2', 'Unnamed: 3'], axis=1)\n",
    "\n",
    "w1.columns = ['日時','天気'] \n",
    "w2.columns = ['日時','天気'] \n",
    "w3.columns = ['日時','天気'] \n",
    "\n",
    "weather = pd.concat([w1,w2,w3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#今回使用するリストはこれ\n",
    "column_list = ['取引時間', '取引連番','ノードNO']\n",
    "df = df_tempo[column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取引時間から時間だけを取り出しておく\n",
    "df['取引時間'] = pd.to_datetime(df['取引時間'])\n",
    "#df['取引時間'] = df['取引時間'].dt.strftime('%Y%m%d%H%M').astype(int)\n",
    "#曜日ダミー出す用\n",
    "df1=df[['取引連番','取引時間','ノードNO']]\n",
    "#それ以外を取引連番毎に結合\n",
    "df2=df.groupby('取引連番').agg({'ノードNO':np.mean,'取引時間':np.max})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20日（Tポイント1.5倍）でダミー\n",
    "dm_20 = pd.get_dummies(df1['取引時間'].dt.strftime('%d') == '20')\n",
    "df1['20日'] = dm_20[True]\n",
    "\n",
    "#水曜なら１の水曜ダミーと木曜なら１の木曜日ダミーを作成する\n",
    "dm_m = pd.get_dummies(df1['取引時間'].dt.strftime('%a') == 'Mon')\n",
    "df1['Mon'] = dm_m[True]\n",
    "\n",
    "dm_w = pd.get_dummies(df1['取引時間'].dt.strftime('%a') == 'Wed')\n",
    "df1['Wed'] = dm_w[True]\n",
    "dm_Th = pd.get_dummies(df1['取引時間'].dt.strftime('%a') == 'Thu')\n",
    "df1['Thu'] = dm_Th[True]\n",
    "\n",
    "#取引連番毎に結合\n",
    "newdf1 = df1.groupby('取引連番').agg(np.mean)\n",
    "\n",
    "#列名変える\n",
    "newdummy = newdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#こっからレジ混雑の話\n",
    "df_regi_1 = df2[df2['ノードNO'] == 1] #レジ1のみ抽出\n",
    "df_regi_101 = df2[df2['ノードNO'] == 101] #レジ101のみ抽出\n",
    "df_regi_102 = df2[df2['ノードNO'] == 102] #レジ102のみ抽出\n",
    "df_regi_103 = df2[df2['ノードNO'] == 103] #レジ103のみ抽出\n",
    "df_regi_104 = df2[df2['ノードNO'] == 104] #レジ104のみ抽出\n",
    "df_regi_105 = df2[df2['ノードNO'] == 105] #レジ104のみ抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#日付ごとの引き算して結合（それぞれで）\n",
    "diff_1=df_regi_1['取引時間'].diff()\n",
    "regi_1 = pd.concat([df_regi_1, diff_1], axis=1)\n",
    "regi_1.columns = ['ノードNO','取引時間','経過時間']\n",
    "#後々「取引を行ったレジ数」を計算する時のために、ノードNOのダミー変数を作る\n",
    "regi_1['1']=1\n",
    "\n",
    "#diffは日付ごとの引き算\n",
    "diff_101=df_regi_101['取引時間'].diff()\n",
    "regi_101 = pd.concat([df_regi_101, diff_101], axis=1)\n",
    "regi_101.columns = ['ノードNO','取引時間','経過時間']\n",
    "regi_101['101']=1\n",
    "\n",
    "diff_102=df_regi_102['取引時間'].diff()\n",
    "regi_102 = pd.concat([df_regi_102, diff_102], axis=1)\n",
    "regi_102.columns =  ['ノードNO','取引時間','経過時間']\n",
    "regi_102['102']=1\n",
    "\n",
    "diff_103=df_regi_103['取引時間'].diff()\n",
    "regi_103 = pd.concat([df_regi_103, diff_103], axis=1)\n",
    "regi_103.columns = ['ノードNO','取引時間','経過時間']\n",
    "regi_103['103']=1\n",
    "\n",
    "diff_104=df_regi_104['取引時間'].diff()\n",
    "regi_104 = pd.concat([df_regi_104, diff_104], axis=1)\n",
    "regi_104.columns =  ['ノードNO','取引時間','経過時間']\n",
    "regi_104['104']=1\n",
    "\n",
    "diff_105=df_regi_105['取引時間'].diff()\n",
    "regi_105 = pd.concat([df_regi_105, diff_105], axis=1)\n",
    "regi_105.columns =  ['ノードNO','取引時間','経過時間']\n",
    "regi_105['105']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全部合わせる\n",
    "regi_all = pd.concat([regi_1, regi_101, regi_102, regi_103, regi_104, regi_105], axis=0)\n",
    "train_all = pd.concat([regi_all,newdummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#混雑（前後の時間差）が分かればよいため各レジ最初の決済（欠損値）削除\n",
    "train_all=train_all.dropna(subset=['経過時間'])\n",
    "#経過時間を秒数に変える\n",
    "train_all['経過時間']=train_all['経過時間'].dt.seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本作業"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=train_all #名前　a　に変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2分ずつ並んだら混雑とみなすためダミー化　各レジで1がどれだけ連続しているかをこれから見る\n",
    "a['経過時間'] = pd.get_dummies(a['経過時間']>120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a.groupby(pd.Grouper(key='取引時間',freq='10min')).agg({'経過時間':np.sum,'20日':np.mean,'Mon':np.mean,'Wed':np.mean,'Thu':np.mean,'1':np.mean,'101':np.mean,'102':np.mean,'103':np.mean,'104':np.mean,'105':np.mean}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=c.dropna(subset=['20日'])\n",
    "c=c.fillna(0)\n",
    "c['取引有無'] = pd.Series(c['1']+c['101']+c['102']+c['103']+c['104']+c['105'], index=c.index )\n",
    "c['混雑有無']=0\n",
    "c.loc[c['経過時間'] >= 3, '混雑有無'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c['year']=  c['取引時間'].dt.strftime('%Y').astype(int)\n",
    "c['month']= c['取引時間'].dt.strftime('%m').astype(int)\n",
    "c['day']= c['取引時間'].dt.strftime('%d').astype(int)\n",
    "c['hour']= c['取引時間'].dt.strftime('%H').astype(int)\n",
    "c['min']= c['取引時間'].dt.strftime('%M').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['日時'] = pd.to_datetime(weather['日時'])\n",
    "weather['year']=  weather['日時'].dt.strftime('%Y').astype(int)\n",
    "weather['month']= weather['日時'].dt.strftime('%m').astype(int)\n",
    "weather['day']= weather['日時'].dt.strftime('%d').astype(int)\n",
    "weather['hour']= weather['日時'].dt.strftime('%H').astype(int)\n",
    "#天気が車使うときか否かでダミー化(9-19)\n",
    "weather['天気']=weather['天気'].astype(int)\n",
    "weather.loc[weather['天気']<9,['天気']]=0\n",
    "weather.loc[weather['天気']>19,['天気']]=0\n",
    "weather.loc[weather['天気']>=9,['天気']]=1\n",
    "weather = weather[['year','month','day','hour','天気']]\n",
    "#weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9霧雨\n",
    "10雨\n",
    "11みぞれ\n",
    "12雪\n",
    "13あられ\n",
    "14ひょう\n",
    "15雷\n",
    "16しゅう雨止み間の雨\n",
    "17着氷性の雨\n",
    "18着氷性の霧雨\n",
    "19しゅう雪止み間の雪\n",
    "の時は車だから交通手段が別(1とする)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#共通列を持つものでweatherとsakura_dataをまとめる\n",
    "sakura_all = pd.merge(c, weather, on=['year', 'month','day','hour'])\n",
    "#sakura_all.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sakura_all.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちなみにsakura_allとsakura_dataで行数違うのは2020年8月分があるかないか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = sakura_all.drop(['1','101','102','103','104','105','経過時間'], axis=1)\n",
    "#d2.head(300)\n",
    "#「最適開放レジ数」の列を追加\n",
    "d2['最適開放レジ数'] = pd.Series(d2['混雑有無']+d2['取引有無'], index=d2.index )\n",
    "#列名の変更\n",
    "d2.columns = ['取引時間','20日','Mon','Wed','Thu','開放レジ数','混雑したレジの有無','year','month','day','hour','min','天気','最適開放レジ数']\n",
    "#print(d2.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d2.groupby(pd.Grouper(key='取引時間',freq='1h')).agg({'20日':np.mean,'Mon':np.mean,'Wed':np.mean,'Thu':np.mean,'hour':np.mean,'天気':np.mean,'最適開放レジ数':np.max}).reset_index()\n",
    "d2=d2.dropna(subset=['20日'])\n",
    "d2['20日'] = pd.Series(round(d2['20日']), index=d2.index )\n",
    "d2['Mon'] = pd.Series(round(d2['Mon']), index=d2.index )\n",
    "d2['Wed'] = pd.Series(round(d2['Wed']), index=d2.index )\n",
    "d2['Thu'] = pd.Series(round(d2['Thu']), index=d2.index )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainデータフレーム作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = d2[(d2['取引時間'] > dt.datetime(2017,9,1)) & (d2['取引時間'] < dt.datetime(2020,8,31))]\n",
    "train = e[['hour','20日','Mon','Wed','Thu','天気','最適開放レジ数']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testデータフレーム作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = d2[(d2['取引時間'] >= dt.datetime(2020,8,31)) & (d2['取引時間'] < dt.datetime(2020,9,1))]\n",
    "test = f[['hour','20日','Mon','Wed','Thu','天気','最適開放レジ数']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#機械学習\n",
    "#予測モデルの作成\n",
    "y_train=train[['最適開放レジ数']]\n",
    "x_train=train[['hour','20日','Mon','Wed','Thu','天気',]]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正規化\n",
    "sscaler = preprocessing.StandardScaler()\n",
    "sscaler.fit(x_train)\n",
    "xss_sk = sscaler.transform(x_train) \n",
    "sscaler.fit(y_train)\n",
    "yss_sk = sscaler.transform(y_train)\n",
    "\n",
    "#print(xss_sk)\n",
    "#print(yss_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#予測\n",
    "y_test=test[['最適開放レジ数']]\n",
    "x_test=test[['hour','20日','Mon','Wed','Thu','天気']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## light GBM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda install -c conda-forge lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import pandas as pd # 基本ライブラリ\n",
    "import numpy as np # 基本ライブラリ\n",
    "import matplotlib.pyplot as plt # グラフ描画用\n",
    "import seaborn as sns; sns.set() # グラフ描画用\n",
    "import warnings # 実行に関係ない警告を無視\n",
    "warnings.filterwarnings('ignore')\n",
    "import lightgbm as lgb #LightGBM\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split # データセット分割用\n",
    "from sklearn.metrics import accuracy_score # モデル評価用(正答率)\n",
    "from sklearn.metrics import log_loss # モデル評価用(logloss)     \n",
    "from sklearn.metrics import roc_auc_score # モデル評価用(auc)\n",
    "\n",
    "# データフレームを綺麗に出力する関数\n",
    "import IPython\n",
    "def display(*dfs, head=True):\n",
    "    for df in dfs:\n",
    "        IPython.display.display(df.head() if head else df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習\n",
    "model = lgb.LGBMClassifier() # モデルのインスタンスの作成\n",
    "model.fit(x_train, y_train) # モデルの学習\n",
    "\n",
    "# テストデータの予測クラス (予測クラス(0 or 1 or 2)を返す)\n",
    "y_pred = model.predict(x_test)\n",
    "# テストデータのクラス予測確率 (各クラスの予測確率 [クラス0の予測確率,クラス1の予測確率,クラス2の予測確率] を返す)\n",
    "y_pred_prob = model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル評価\n",
    "# acc : 正答率\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Acc :', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ランダムフォレスト（こちらを選択）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 識別モデルの構築\n",
    "random_forest = RandomForestClassifier(max_depth=30, n_estimators=30, random_state=42)\n",
    "random_forest.fit(x_train, y_train)\n",
    "\n",
    "# 予測値算出\n",
    "y_pred = random_forest.predict(x_test)\n",
    "\n",
    "#モデルを作成する段階でのモデルの識別精度\n",
    "trainaccuracy_random_forest = random_forest.score(x_train, y_train)\n",
    "print('TrainAccuracy: {}'.format(trainaccuracy_random_forest))\n",
    "\n",
    "#作成したモデルに学習に使用していない評価用のデータセットを入力し精度を確認\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {}'.format(accuracy_random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False, fmt='d', cmap='RdPu')\n",
    "plt.xlabel('predicted class')\n",
    "plt.ylabel('true value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数の重要度を可視化\n",
    "importance = pd.DataFrame({ '変数' :x_train.columns, '重要度' :random_forest.feature_importances_})\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=test\n",
    "output['最適開放レジ数予測'] = y_pred\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8), dpi=100)\n",
    "plt.plot(output['hour'], output['最適開放レジ数'], marker=\"o\")\n",
    "plt.title('The hourly optimal number of cashiers')\n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('the opitimal number of cashiers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8), dpi=100)\n",
    "plt.plot(output['hour'], output['最適開放レジ数予測'], marker=\"o\")\n",
    "plt.title('precision(The hourly optimal number of cashiers)')\n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('the opitimal number of cashiers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflowの回帰問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こちらや重回帰などは今回多クラス分類のため選択せず"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[len(x_train.keys())]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "example_batch = x_train[:10]\n",
    "example_result = model.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# エポックが終わるごとにドットを一つ出力することで進捗を表示\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 100 == 0: print('')\n",
    "    print('.', end='')\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "history = model.fit(\n",
    "  x_train, y_train,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "  callbacks=[PrintDot()])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plot_history(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Abs Error [MPG]')\n",
    "  plt.plot(hist['epoch'], hist['mae'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mae'],\n",
    "           label = 'Val Error')\n",
    "  plt.ylim([0,5])\n",
    "  plt.legend()\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "  plt.plot(hist['epoch'], hist['mse'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mse'],\n",
    "           label = 'Val Error')\n",
    "  plt.ylim([0,20])\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loss, mae, mse = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred = model.predict(x_test).flatten()\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output=test\n",
    "output['最適開放レジ数予測'] = y_pred\n",
    "output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(16, 8), dpi=100)\n",
    "plt.plot(output['hour'], output['最適開放レジ数'], marker=\"o\")\n",
    "plt.title('The hourly optimal number of cashiers')\n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('the opitimal number of cashiers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(16, 8), dpi=100)\n",
    "plt.plot(output['hour'], output['最適開放レジ数予測'], marker=\"o\")\n",
    "plt.title('precision(The hourly optimal number of cashiers)')\n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('the opitimal number of cashiers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow多クラス分類問題（softmax）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow と tf.keras のインポート\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# ヘルパーライブラリのインポート\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import kerastuner as kt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# one-hotエンコーディング\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Input(len(x_train.keys())),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(7, activation='softmax')#y_trainが7列だから\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3cellハイパーチューニング"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential([keras.layers.Input(len(x_train.keys())),keras.layers.Dense(100, activation='relu'),keras.layers.Dense(7, activation='softmax')])#y_trainが7列だから\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                    loss=keras.losses.categorical_crossentropy(from_logits=True),\n",
    "                    metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory=\"C:\\\\Users\\\\taban\\\\Desktop\\\\3年講義\\\\秋学期\\\\マネジメント演習\",\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tuner.search(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=test\n",
    "output['最適開放レジ数予測'] = np.argmax(y_pred, axis=1)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8), dpi=100)\n",
    "plt.plot(output['hour'], output['最適開放レジ数予測'], marker=\"o\")\n",
    "plt.title('precision(The hourly optimal number of cashiers)')\n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('the opitimal number of cashiers')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
